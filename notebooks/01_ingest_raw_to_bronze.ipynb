{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaa5a991-78e6-4b68-9e4a-c3d990ea1a31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Notebook\n",
    "# ---------------------------------------------------------\n",
    "# Notebook 01: Ingest Raw Source Files into Bronze Layer\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "from pyspark.sql.functions import current_timestamp, input_file_name\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# -----------------------------\n",
    "# 1. File Paths\n",
    "# -----------------------------\n",
    "patient_src_path = \"dbfs:/FileStore/Mini_Project/Source_data/Patient_Source.csv\"\n",
    "insurance_src_path = \"dbfs:/FileStore/Mini_Project/Source_data/Insurance_Source.csv\"\n",
    "\n",
    "bronze_patient_path = \"dbfs:/FileStore/Mini_Project/bronze/patient_bronze\"\n",
    "bronze_insurance_path = \"dbfs:/FileStore/Mini_Project/bronze/insurance_bronze\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Read Raw Patient File\n",
    "# -----------------------------\n",
    "df_patient_raw = (\n",
    "    spark.read\n",
    "         .option(\"header\", True)\n",
    "         .option(\"inferSchema\", True)\n",
    "         .csv(patient_src_path)\n",
    "         .withColumn(\"ingest_time\", current_timestamp())\n",
    "         .withColumn(\"source_file\", input_file_name())\n",
    ")\n",
    "\n",
    "print(\"Patient_RAW Schema:\")\n",
    "df_patient_raw.printSchema()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Write Patient Data to Bronze (Delta)\n",
    "# -----------------------------\n",
    "df_patient_raw.write.mode(\"overwrite\").format(\"delta\").save(bronze_patient_path)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS patient_bronze\n",
    "    USING DELTA\n",
    "    LOCATION 'dbfs:/FileStore/Mini_Project/bronze/patient_bronze'\n",
    "\"\"\")\n",
    "\n",
    "print(\"Patient Bronze Table Created Successfully.\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Read Raw Insurance File\n",
    "# -----------------------------\n",
    "df_insurance_raw = (\n",
    "    spark.read\n",
    "         .option(\"header\", True)\n",
    "         .option(\"inferSchema\", True)\n",
    "         .csv(insurance_src_path)\n",
    "         .withColumn(\"ingest_time\", current_timestamp())\n",
    "         .withColumn(\"source_file\", input_file_name())\n",
    ")\n",
    "\n",
    "print(\"Insurance_RAW Schema:\")\n",
    "df_insurance_raw.printSchema()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Write Insurance Data to Bronze (Delta)\n",
    "# -----------------------------\n",
    "df_insurance_raw.write.mode(\"overwrite\").format(\"delta\").save(bronze_insurance_path)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS insurance_bronze\n",
    "    USING DELTA\n",
    "    LOCATION 'dbfs:/FileStore/Mini_Project/bronze/insurance_bronze'\n",
    "\"\"\")\n",
    "\n",
    "print(\"Insurance Bronze Table Created Successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingest_raw_to_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
